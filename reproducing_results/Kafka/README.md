Reproducing Results for Kafka
=======
The scripts in this directory can be used to reproduce Kafka (v2.13-2.6.0) results that are presented in a paper titled "Toward a Generic Fault Tolerance Technique for Partial Network Partitioning" that is published in OSDI'20. Results in the paper were generated by running the experiments on 20 [xl170](http://docs.cloudlab.us/hardware.html) nodes in Utah cluster on [CloudLab](https://www.cloudlab.us/). The scripts were tested with Python3. 

Description of the scripts
-------
Teh following is a brief description for each script in this directory:

* config: This script contains configuration parameters that is needed to run the experiments. Those parameters are described below in the *Running the Experiment* section.
* deploy_kafka.py: this script deploys Kafka brokers on the cluster specified in `config.py` file.
* stop_kafka.py: this script stops all Kafka instances that are running on the  cluster specified in `config.py` file.
* run_benchmark.py: this scripts runs the Kafka producers to measure the throughout of Kafka. The script takes one argument which specifies the number of producers to run. Producers will be distributed over the client nodes (i.e., nodes that are not part of Kafka cluster).
* run_exp.py: The scripts runs multiple experiments to get the performance of Kafka with different number of clients. This script takes three arguments: `min_num_clients, max_num_clients, step`. First experiments starts with `min_num_clients` clients and then it increases the number of clients by `step` until it reaches `max_num_clients`. Clients will be distributed over the machines that are in the cluster but were not used in the Kafka cluster. The client will run in parallel, and each client will produce to a topic. Finally, the script writes the throughput results to a file stored in `./tmp/results.csv`. As an example, `python run_exp.py 2 4 2` will generate the throughput of Kafka with 2 and 4 clients. The output `results.csv` file will look something like this:

number of producers | throughput
------------------- | ----------
2 | 200000
4 | 400000   


Prerequisites
-------
1- Install Java.  
```bash
$ apt-get install default-jdk -y
```
2- install kafka v2.13-2.6.0 from the website: https://www.apache.org/dyn/closer.cgi?path=/kafka/2.6.0/kafka_2.13-2.6.0.tgz. 


Running the Experiment
-------
1- Set the following variables in the config.py file: 
* KAFKA_HOME: the directory at which Kafka is installed and it should be the same for all nodes in the cluster.
* NODES_IPS: the ip addresses of all nodes in teh cluster. 
* KAFKA_DATA_DIR: the directory at which Kafka logs and config files will be stored.
* KAFKA_PORT: Kafka brokers will listen at this port
* ZOOKEEPER_PORT: ZooKeeper will listen at this port
* REPLICATION_FACTOR: the replication factor for Kafka. 
* USER_NAME: ssh username which is needed to ssh into other nodes and run commands. Set this to `None` if not needed. 
* SSH_KEY_PATH: the path to ssh private key. Set this to `None` if not needed.

2- start Kafka cluster by running  
```bash 
python deploy_kafka.py
```
This script starts a ZooKeeper instance on the first node in `NODES_IPS` and N Kafka brokers on the next N nodes, where N = `REPLICATION_FACTOR` configuration parameter.

3- Start the throughput experiment bu running `run_exp.py` script.
```bash 
python run_exp.py min_num_clients max_num_clients step
```

Reproducing Results
-------
In order to reproduce the results in the paper, you have to run the experiment (as described above) with and without Nifty and compare the results by combining the generated `result.csv` files and then plotting a similar figure to the one in the paper. According to our results, Nifty does not add noticeable overhead. Please refer the `deploy` folder to check how to deploy Nifty.